# Reproducibility; Research Objects (RO-Crate) and Common Workflow Language (CWL)
**by Stian Soiland-Reyes**  

## From session 3 - [Human factors and new development in preserving and sustaining research software](/wosss21/agenda#session-3)  

### Resources

A [video](https://www.youtube.com/watch?v=vNHqTcHnfyI&list=PLXAvKzjdTsrxFqbjWtxHjfJc0RN6jMwZg&index=19) and [slides](https://slides.com/soilandreyes/2021-10-07-reproducibility-ro-crate-cwl) are available.

### Summary

The use of digital methods and computational analysis is now ubiquitous across sciences and research disciplines. However, there is a growing concern that while modern computing accelerates scientific development and progress, it can come at the cost of reduced reproducibility and a difficulty of communicating the methodology to other researchers, particularly through traditional scholarly articles as text and static figures. [Research Objects](https://www.research.manchester.ac.uk/portal/en/publications/why-linked-data-is-not-enough-for-scientists(394d2487-5598-4e1e-a0c1-d67ad65d7947).html) have been proposed as a unit of scholarly communication, gathering raw data, software, results, figures and documents, described and inter-related using Linked Data, and as an aggregation cited by its own persistent identifier.

[RO-Crate](https://www.researchobject.org/ro-crate/) is a realisation of Research Objects using off the shelf Web standards (JSON-LD) and vocabularies  (schema.org), with a developer-friendly lightweight approach and a set of best-practice guides for capturing “just enough” structured metadata, being interoperable with Linked Data technologies, and extensible for domain-specific needs.  RO-Crate is being developed as a community-led project, supported by open source tools, and is being adapted for a wide range of different scientific domains and use cases.

### Transcript

#### Keywords

workflow, data, crate, metadata, ro, case, file, tool, called, reproducibility, talk, run, describe, tie, coming, research, command line tools, work, containers, link

#### Text

Hopefully you can see this scream out? If not. So I think it was great to have that. It's almost like a setup for what I wanted to talk about with you. So I'm very happy about that. So I'm coming into this from the area of reproducibility. Now we notice lots of other areas in science that also is difficult with reproducibility. But we're thinking particularly about computational reproducibility, because you would think, like, you're just explaining, you've got an older computer, it should be possible to just run it again. Right. But that's not how it's reported today. So this is a really brilliant paper, I would say, in meta genomics, which is has a massive methods section, if you just highlight out here you see it, these are all the tools that it's using, I do have version, numbers, parameters, data source, and so on, kind of the details are there. Superficially, at least, but for me to do run same, will take me a few weeks to build off again, that workflow, right just to see if this is something I want to do. And they haven't moved on to perimeter. So David have provided the code. So you have those things there. But now all those details are gone, right? The version numbers, all those things that the machine could process and find out more about, they're all gone? Why is this No fair aspect anymore about the software? So how do I get about getting this to work with all the things it needs? So we heard about reference from Carol. And I guess I'm going to convince you again, you should should try using workflow systems. And particularly are interested in having the abstraction to get from a workflow system that is not just this tangled mess we heard about, but you can actually almost like get a diagram out of here for many of the system. But that is to form this quite a few workflow systems. So we'll be keeping a list of the wiki, please go and add your favourite if they're not there. So we have 300. Last time I checked. And so how do you choose which one? And how do you make sure your computational analysis your method actually works? Across the server for a system? Because why if you tied into one of them, now you're locked into lots of different things. So that's the motivation we had when we made the common overflow language. So we found that lots of these all what they really do, before they go special is just to call some command line tools. One of my colleagues has said, it's just a make file, isn't it? Yes, this make file on steroids, right. All of these are really just chaining together command line tools, But with parallelisation container images, a so on I come over for libraries have this is the base point. And you see all of the here, you have multiple engines connecting and growing list of people who are adopting it. And the way and here is an interview with the same authors of the paper he saw before where he's talking about how now by moving to common workflow for language, he was actually able to collaborate with basically his competitor, because they had lots of things in common, even though they were doing their analysis in different ways. Most notably, they could share the way they're called the tools together, why so they could collaborate on the boring bits of the workflow while they could focus on the science. So basically, this is basically a very small example of how that would work, right, because you have the main, common workflow language file on here. So it is a language, it's a file, you can type in your input and output and then a series of steps. But then each step is a file that is separated out. And that's how you've kind of wrapped the tool you want to run. So that is the main reason why you could reuse them again in many different workflows. And then of course, in there, you would have, again inputs and outputs to that particular tool, or more precisely, that usage of a tool, right, because a command line could be doing many different things, depending on the options, and so on. So that's where your tie in how to actually run it, right. But we need to actually have something to run. So it could just be all we assume it's already installed with that's not good enough. You should you can provide Docker images and so on then downloaded directly and you can just actually a list as you can have multiple fallbacks in case you're running, for instance, on HPC. And you cannot use Docker containers, in case you haven't heard about containers is basically a way to wrap a kind of mini operating system with all the things you need to run one particular tool. That's the kind of philosophy that means each of the step can have different environments for how you run that's common across many workflow systems now, which is helping a lot on reproducibility and more importantly, reusability.
 
Now let's have a look about research objects. So now when we introduced this concept research object, you see back then 2011 That was a main ingredient of that wants to save. You should use workflows to tie together the software you're using to analyse and run your data. But you need the other things you need. You need an actual data reference in there and Then you have the results coming out. And then you tie these things together, then now you're starting to upload something that is more accessible and more complete than this old PDF that you have to read, because now the computer can also access it. Now the latest instance of the research object concept is something we call ro-crate. So heavy kind of going to be back to basics, because we were kind of lost in the semantic web land for a way. But now we kind of try to make it a bit more concrete for the base use case. So this is my co chair, Peter Sefton in the failure who have presented this poster from what we now see as the kind of starting point for packaging some data, you just have some files on the disk, you should be able to just describe them into a good piece of metadata and put them in the context and describe how they came to be. And that is by adding ro-crate metadata document. Now in there, you can not just add all your data files and so on, you can also add in things in a world that could be a reference datasets and so on things to download, because it'd be instruments could be places you've been to, it could be people, it could be organisations, and so on, as long as you have some kind of identifier, or at least you can describe it in a goes. And that is completing the contextual picture of the research, okay. And then here is Peters very simple example. Because we should be able to handle the basic sample, right, which is, we just get some rubbish filenames coming out of our camera, this could be like electron microscope, anything like that, as well, we have much worse file names, and you want to give it a bit more descriptions here we are just giving it a name, so that you have a little JSON file for that. But then you can push a button and you also get an HTML rendering for that. Why do we emphasise that? Well, we don't want to tie yourself to particular infrastructures and platforms and so on. So when you store your research data, you should also be able to have a human readable version of that accessible, so the HTML file actually stored with the data and the metadata. And then you can add some provenance to connect all these things together. And this is what I'm going to talk a bit more about in a second. Now, I can go into the ticky deep dive, but we don't really have time for that. But base needless to say that we have made a specification that says how you use something called schema.org, for connecting up the different things you want to describe. So basically, we're using existing technologies like JSON LD, which is a way to make link data in fairly simple data structures, and a vocabulary called schema.org, which many web developers will recognise because that is what used to give markup on your website so that Google can give you these little info boxes, and so on. But it's also quite powerful for these kinds of things. Because most of the kind of things in the world already exist in there, and you can specialise it, like we have done with bio schemas for the bio domain. So here's basically a shortcut of how it works. We have these identifiers, the link to different blocks together. Now, most people, they don't want to see that, or they want to just click a button and get on with their life, right. So we want to show a bit of the different kind of tools we have the basic tool is spawn, creating for that use case of having just a bunch of files. So here, you can click and describe individual files, and you can add into different contextually descriptions and so on. And it will make the metadata for you. And then again, the rendering here. So you'll see that that kind of rendering, where you can navigate into the different things even though it's just a single file. So that's my argument that FAIR is not just machine readable, keep the human in the loop, right, so don't make it too inaccessible.
 
Now, so one, I want to link back to the first session where we heard about cultural heritage. And that's also been another use case. So here, ro-crate is actually underneath the hood. So this is a project called par DESeq. In the Pacific in Australia region, which is capturing people speaking the native language itself, our risk of extinction, not the people but languages. And there's all these recordings in the wild. And you see some of them are very old and handwritten and so on, but there have been digitised and put together and put on a website so you can access them and then put in repositories. And this is all when they've had all this metadata in here so you can filter and search for them. But this is all coming from our ro-crate which you cannot see unless you push the magic button. I want to point out here that when we talk about FAIR, it does actually say that it is permissible that you cannot access that you need to request access to data and that's the case here because this is human subjects you need to follow a set of regulations. before you're allowed access to the data. So here, it's very nice to have the distinction between the metadata and the actual data, like the recordings in this case. That comes in to licencing, and so on.
 
I want to show you a bit more about how to do things in workflows. So Carole showed you a bit of our workflow, hub, and so on. And where we use our ro-crate to capture data about workflows. And they can also do that for capturing the run, which we saw how I showed you this massive list of things you could capture the requisite could help you with that. And I want to show you a bit more about the tools, because the basic case is you just use a tool and then you want to describe it. But it could be that you have a very complicated case, like we have here, this is the building blocks we have in BioExcel. So we have taken research software and wrapped them and deal with different ways. So they were a bit messy, like we heard Colin talking about before, and then we packaged them up. And then you can use them a different workflow systems. But that means that now our workflow is actually it's already turned into this kind of box of a box of a box, right, because we if we now go into ro-crate and look at the workflow, here, we have these different building blocks being used. So here's one, and then here, you can add for that particular building block all different references. So here you'll see the building the containers, the python, and so on. And then you can go in there again and say which stuff does that use, and that might have a different set of citations and so on. And that's basically where is the power of the ro-crate and that you can dig in where you need to. And the, in the case of people haven't already provided a codemeta and that kind of useful thing. You can still provide that metadata on their behalf. So I said you can read a lot more about that in a paper which I have linked in there. And I want to thank the ever growing community of ro-crate people.



